

# app/main.py
import json
from typing import Any, Dict, List, AsyncGenerator
from fastapi import FastAPI, Body, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from app import mock_geo  # å°±æ˜¯ä¸Šé¢æ–°å»ºçš„æ¨¡å—
from app import db_json
from pydantic import BaseModel
from typing import Optional
import anyio
import base64
import httpx
import asyncio
from collections import Counter
from .mock_geo import BASE as POI_SEED
from . import pois_json
import time




#from app import rag_store

# ==== Strands + Ollamaï¼ˆæŒ‰ä½ æä¾›çš„ç”¨æ³•ï¼‰====
from strands import Agent
from strands.agent.conversation_manager import SlidingWindowConversationManager
from strands.models.ollama import OllamaModel
import hashlib
from math import isnan


# === å›¾è¡¨è§£è¯»å°å·¥å…· ===
def _aggregate_stats(rows: list[dict]) -> dict:
    from collections import Counter
    import math, statistics as st
    vendors = Counter([(r.get("vendor") or "æœªçŸ¥") for r in rows])
    statuses = Counter([(r.get("status") or "æœªçŸ¥").lower() for r in rows])
    bands = Counter([(r.get("band") or "æœªçŸ¥") for r in rows])
    times = [int(r.get("updated_at") or 0) for r in rows if r.get("updated_at")]
    hist = None
    if times:
        times_sorted = sorted(times)
        hist = {
            "min": times_sorted[0],
            "p50": times_sorted[len(times_sorted)//2],
            "max": times_sorted[-1],
            "mean": int(st.mean(times)),
        }
    top_vendor = vendors.most_common(1)[0][0] if vendors else None
    return {
        "n": len(rows),
        "vendor_counts": dict(vendors),
        "status_counts": dict(statuses),
        "band_counts": dict(bands),
        "updated_at_summary": hist,
        "top_vendor": top_vendor,
    }

def _classify_kind(prompt: str) -> str:
    p = prompt or ""
    if re.search(r"(ç”œç”œåœˆ|donut)", p, re.I): return "donut"
    if re.search(r"(é¥¼å›¾|pie)", p, re.I): return "pie"
    if re.search(r"(çƒ­åŠ›|heatmap)", p, re.I): return "heatmap"
    if re.search(r"(å †å |stack)", p, re.I): return "stacked"
    if re.search(r"(ç›´æ–¹|hist)", p, re.I): return "hist"
    if re.search(r"(æ°´å¹³|horizontal|barh|hbar)", p, re.I): return "horizontal"
    return "bar"  # é»˜è®¤æŸ±çŠ¶


# è¿æ¥æœ¬åœ° Ollamaï¼ˆç¡®ä¿ ollama serve åœ¨è·‘ï¼Œä¸”å·² pull å¯¹åº”æ¨¡å‹ï¼‰
model = OllamaModel(
    host="http://127.0.0.1:11434",
    model_id="qwen3:1.7b",   # æ”¹æˆä½ æœ¬æœºå¯ç”¨æ¨¡å‹
)
OLLAMA_HOST = "http://127.0.0.1:11434"
OLLAMA_MODEL_ID = "qwen3:1.7b"


agent = Agent(
    model=model,
    conversation_manager=SlidingWindowConversationManager(window_size=2),
    system_prompt="You are a helpful assistant that provides concise responses.",
    callback_handler=None,
)

# ===== æ”¾åœ¨ main.py é¡¶éƒ¨å…¶å®ƒå‡½æ•°æ— =====
import re
from . import chart_specs


async def stream_from_ollama(prompt: str):
    """
    ç›´æ¥å¯¹æ¥ Ollama /api/generate çš„æµå¼æ¥å£ï¼š
    ä¸€è¡Œä¸€ä¸ª JSONï¼š{"response": "...", "done": false} ... {"done": true}
    """
    async with httpx.AsyncClient(timeout=None) as client:
        async with client.stream(
            "POST",
            f"{OLLAMA_HOST}/api/generate",
            json={
                "model": OLLAMA_MODEL_ID,
                "prompt": prompt,
                "stream": True,
            },
            headers={"Accept": "application/json"},
        ) as resp:
            resp.raise_for_status()
            async for line in resp.aiter_lines():
                if not line:
                    continue
                try:
                    obj = json.loads(line)
                except Exception:
                    continue
                if "response" in obj:
                    # è¿™é‡Œè¿”å›â€œå¢é‡â€
                    yield obj["response"]
                if obj.get("done"):
                    break


# === åœ¨ main.py é¡¶éƒ¨ regex åŒºåŸŸé™„è¿‘æ–°å¢ ===
INLINE_CHART_HINT_RE = re.compile(r"(ä¸‹è½½|å¯¼å‡º|ä¿å­˜|å¦å­˜|ä¿å­˜ä¸º|å¤åˆ¶|æ‹·è´|æ‹·è´ä»£ç |å¤åˆ¶ä»£ç |æ‹¿ä»£ç |æ‹¿å›¾|å¯¼å‡ºå›¾ç‰‡|ä¿å­˜å›¾ç‰‡|å›¾ç‰‡|png|svg|pdf|json|JSON|code|CODE)", re.I)
OVERVIEW_HINT_RE     = re.compile(r"(å…¨éƒ¨|æ‰€æœ‰|å…¨å¥—|æ€»è§ˆ|overview|å…¨å›¾)", re.I)

def wants_inline_chart(text: str) -> bool:
    """ç”¨æˆ·æ˜ç¡®æåˆ°ä¸‹è½½/å¤åˆ¶ç­‰ â†’ åœ¨èŠå¤©æ°”æ³¡å†…å†…åµŒå›¾"""
    p = text or ""
    return bool(INLINE_CHART_HINT_RE.search(p)) and not OVERVIEW_HINT_RE.search(p)


# 1) æ–°å¢ï¼šæŒ‰â€œç«™å/åç§°/å«/å¼•å·â€æå–åå­—ï¼Œå¹¶ç”¨æœ¬åœ°åº“è§£ææˆ station
NAME_HINT_RE = re.compile(r"(?:ç«™å|åç§°|åå­—|åä¸º|å«)\s*([^\sï¼Œã€‚,:;!?ã€ã€‘ã€Šã€‹]{2,32})")
QUOTED_NAME_RE = re.compile(r"[â€œ\"']([^â€œ\"']{2,32})[â€\"']")

def extract_station_name(prompt: str) -> str | None:
    if not prompt: return None
    m = QUOTED_NAME_RE.search(prompt) or NAME_HINT_RE.search(prompt)
    if m: return m.group(1)
    # å…œåº•ï¼šåŒ¹é…â€œåŸå¸‚-ç¤ºä¾‹ç«™æ•°å­—â€è¿™ç±»å¸¸è§å‘½å
    m = re.search(r"[\u4e00-\u9fff]{2,8}-?ç¤ºä¾‹ç«™\d{1,3}", prompt)
    return m.group(0) if m else None

def resolve_station_from_prompt(prompt: str) -> dict | None:
    # å…ˆæŒ‰ ID
    sid = extract_station_id(prompt or "")
    if sid:
        s = db_json.get_station(sid)
        if s: return s
    # å†æŒ‰åå­—ï¼ˆå¯ç»“åˆåŸå¸‚ç¼©å°èŒƒå›´ï¼‰
    name = extract_station_name(prompt or "")
    if not name:
        # æ²¡æœ‰æ˜ç¡®åå­—ï¼Œå°±ç”¨ç°æœ‰ TopK é€»è¾‘æŒ‘ä¸€ä¸ªå¼ºç›¸å…³å€™é€‰ï¼ˆé¿å…ççŒœï¼‰
        topk = topk_context_for_prompt(prompt, k=1)
        return topk[0] if topk else None
    city = extract_city(prompt or "")
    items = db_json.load_all()
    cand = [s for s in items if (not city or s.get("city")==city)]
    def score(s):
        n = s.get("name","")
        sc = 0
        if name in n: sc += 5
        if n in name: sc += 4
        # è½»é‡ token å‘½ä¸­
        for t in re.findall(r"[\u4e00-\u9fffA-Za-z0-9\-]+", prompt or ""):
            if t and t in n: sc += 1
        return sc + (1 if city and s.get("city")==city else 0)
    if not cand: return None
    best = max(cand, key=score)
    return best if score(best) >= 2 else None  # é˜ˆå€¼é˜²è¯¯åˆ¤

STATUS_ALIASES = {
    "online": ["online", "åœ¨çº¿", "åœ¨ç½‘", "ä¸Šçº¿"],
    "maintenance": ["maintenance", "ç»´æŠ¤", "æ£€ä¿®", "ä¿å…»"],
    "offline": ["offline", "ç¦»çº¿", "ä¸‹çº¿", "åœæœº"],
}
def normalize_status(s: str) -> str | None:
    s = (s or "").lower()
    for k, vs in STATUS_ALIASES.items():
        if any(v.lower() in s for v in vs):
            return k
    return None

def extract_city_status_count(prompt: str):
    """
    è§£æï¼š'ä¸Šæµ·å‡ ä¸ªæ˜¯onlineçš„' / 'åŒ—äº¬åœ¨çº¿æœ‰å¤šå°‘ä¸ª' / 'æ­å·ç»´æŠ¤çš„æœ‰å‡ ç«™' ç­‰
    è¿”å›: (city, status) æˆ– None
    """
    if not prompt:
        return None
    city = extract_city(prompt)
    if not city:
        return None

    # ç»Ÿä¸€çŠ¶æ€è¯
    STATUS_WORDS = r"(åœ¨çº¿|ç¦»çº¿|ç»´æŠ¤|online|offline|maintenance)"
    # ä¸¤ç§é¡ºåºï¼šâ‘  å…ˆçŠ¶æ€åâ€œå‡ ä¸ª/å¤šå°‘/å‡ â€ï¼›â‘¡ å…ˆâ€œå‡ ä¸ª/å¤šå°‘/å‡ â€åçŠ¶æ€
    pat = re.compile(
        rf"(?:(?P<status1>{STATUS_WORDS}).{{0,8}}?(?:å‡ ä¸ª|å¤šå°‘|å‡ ))|(?:(?:å‡ ä¸ª|å¤šå°‘|å‡ ).{{0,8}}?(?P<status2>{STATUS_WORDS}))",
        re.IGNORECASE,
    )
    m = pat.search(prompt)
    if not m:
        return None
    status_raw = m.group("status1") or m.group("status2")
    status = normalize_status(status_raw)
    if not status:
        return None
    return city, status

# ===== POI + é™„è¿‘æ£€ç´¢ï¼šå·¥å…·å‡½æ•°ï¼ˆæœ€å°ç‰ˆï¼‰ =====

# æ›¿æ¢åŸ NEAR_WORDS_REï¼Œå¹¶æ–°å¢åŸºç«™è¯
NEAR_WORDS_RE = re.compile(r"(é™„è¿‘|å‘¨è¾¹|å‘¨å›´|é‚»è¿‘|å°±è¿‘|å‘¨é­|ä¸€?å…¬é‡Œå†…|æ–¹åœ†|èŒƒå›´å†…|è¿‘å¤„|è¿‘é‚»|è¿‘æ—)", re.I)
BS_WORDS_RE   = re.compile(r"(åŸºç«™|ç«™ç‚¹|5g|4g|å°åŒº|å®ç«™|å¾®ç«™|å®¤åˆ†)", re.I)

# å¯é€‰ï¼šç”¨äºé¿å…æŠŠé“è·¯/è¡Œæ”¿åŒºå½“æˆ POI
ROAD_SUFFIX_RE   = re.compile(r"(è·¯|è¡—|å··|å¤§é“|ç¯è·¯|é«˜é€Ÿ|çœé“|å›½é“|çº¿|å·çº¿)$")
ADMIN_SUFFIX_RE  = re.compile(r"(å¸‚|åŒº|å¿)$")
POI_SUFFIX       = r"(ä¸­å¿ƒ|å¹¿åœº|å•†åœˆ|åŒ»é™¢|è½¦ç«™|å…¬å›­|ä½“è‚²åœº|ä½“è‚²é¦†|æ­¥è¡Œè¡—|æœºåœº|å¤§å¦|å›­åŒº|ç§‘æŠ€å›­|å›­|å¸‚åœº|ç å¤´|æ¸¯|ä¼šå±•ä¸­å¿ƒ|åšç‰©é¦†|ç¾æœ¯é¦†|å›¾ä¹¦é¦†|å¤§å­¦|å­¦é™¢|æ¥ç¦å£«|ä¸‡è±¡åŸ|å¤ªå¤é‡Œ|ä¸‡è¾¾å¹¿åœº)"
LOOSE_POI_BEFORE_NEAR = re.compile(r"([\u4e00-\u9fffA-Za-z0-9Â·]{2,24})(?=(?:çš„)?(?:ä¸€?å…¬é‡Œå†…|æ–¹åœ†|èŒƒå›´å†…)?(?:é™„è¿‘|å‘¨è¾¹|å‘¨å›´))")
LOOSE_POI_BEFORE_BS   = re.compile(r"([\u4e00-\u9fffA-Za-z0-9Â·]{2,24})(?=(?:çš„)?(?:åŸºç«™|ç«™ç‚¹|5G|4G|å°åŒº))", re.I)

def extract_poi_key(prompt: str) -> str | None:
    """ä¸¥æ ¼è§„åˆ™ + æ¾å¼›å…œåº•ï¼šæåˆ° POI ä¸”ç»“åˆâ€œé™„è¿‘/åŸºç«™â€æ—¶è¿”å› POI åï¼›åŸå¸‚/é“è·¯/è¡Œæ”¿åŒºä¼šè¢«è¿‡æ»¤æ‰ã€‚"""
    if not prompt:
        return None

    def _valid(cand: str) -> bool:
        cand = cand.strip()
        if not cand or len(cand) < 2:
            return False
        if cand in CITY_NAMES:
            return False
        if ADMIN_SUFFIX_RE.search(cand):
            return False
        if ROAD_SUFFIX_RE.search(cand):
            return False
        if BS_WORDS_RE.search(cand):  # â€œåŸºç«™/5Gâ€ä¸æ˜¯ POI å
            return False
        return True

    # â€”â€” ä¸¥æ ¼ï¼šå¼•å·ä¼˜å…ˆ â€”â€” 
    m = re.search(r"[â€œ\"']([^â€œ\"']{2,24})[â€\"']", prompt)
    if m:
        cand = m.group(1).strip()
        for cname in CITY_NAMES:
            cand = cand.replace(cname, "")
        cand = cand.strip()
        return cand if _valid(cand) else None

    # â€”â€” ä¸¥æ ¼ï¼šå¸¸è§ POI åç¼€ â€”â€” 
    m = re.search(rf"([\u4e00-\u9fffA-Za-z0-9Â·]{2,24}){POI_SUFFIX}", prompt)
    if m:
        cand = m.group(0)
        for cname in CITY_NAMES:
            cand = cand.replace(cname, "")
        cand = cand.strip()
        if _valid(cand):
            return cand

    # â€”â€” æ¾å¼›å…œåº•ï¼šå¦‚æœå¥å­é‡Œå‡ºç°â€œé™„è¿‘/åŸºç«™â€ï¼ŒæŠ“å…¶å‰é¢çš„çŸ­è¯å½“ POI â€”â€” 
    if NEAR_WORDS_RE.search(prompt) or BS_WORDS_RE.search(prompt):
        for pat in (LOOSE_POI_BEFORE_NEAR, LOOSE_POI_BEFORE_BS):
            m = pat.search(prompt)
            if m:
                cand = m.group(1).strip()
                for cname in CITY_NAMES:
                    cand = cand.replace(cname, "")
                cand = cand.strip()
                if _valid(cand):
                    return cand

    return None

def find_poi_candidates(prompt: str):
    """åªç”¨ POI å…³é”®è¯å¬å›ï¼›city ä»…ä½œè¿‡æ»¤ï¼Œä¸å†æŠŠ city æ‹¼è¿›å…³é”®å­—ã€‚"""
    city_hint = extract_city(prompt or "")
    key = extract_poi_key(prompt or "")
    if not key:
        return [], city_hint
    for cname in CITY_NAMES:
        key = key.replace(cname, "")
    key = key.strip()
    if not key:
        return [], city_hint
    cands = pois_json.search_pois(city=city_hint, name_like=key, limit=12)
    if not cands:
        cands = pois_json.search_pois(name_like=key, limit=12)
    return cands, city_hint


def _haversine_m(lat1, lon1, lat2, lon2) -> float:
    """çƒé¢è·ç¦»ï¼ˆç±³ï¼‰"""
    from math import radians, sin, cos, sqrt, atan2
    R = 6371000.0
    dlat = radians(lat2 - lat1)
    dlon = radians(lon2 - lon1)
    a = sin(dlat/2)**2 + cos(radians(lat1))*cos(radians(lat2))*sin(dlon/2)**2
    c = 2 * atan2(sqrt(a), sqrt(1 - a))
    return R * c

def nearby_stations_by_poi(poi: dict, radius_m: int | None = None, limit: int = 200) -> list[dict]:
    """åœ¨ POI å‘¨è¾¹æŒ‰åŠå¾„ç­›åŸºç«™ï¼ˆç®€å•éå†ï¼Œdemo è¶³å¤Ÿï¼‰ã€‚"""
    lat0, lng0 = float(poi.get("lat")), float(poi.get("lng"))
    #r = int(radius_m or poi.get("radius_m") or 2000)
    r = 5000
    items = db_json.load_all()
    hits = []
    for s in items:
        if poi.get("city") and s.get("city") != poi.get("city"):
            continue  # åŒåŸä¼˜å…ˆï¼Œé¿å…è·¨åŸå™ªå£°
        lat, lng = s.get("lat"), s.get("lng")
        if lat is None or lng is None:
            continue
        d = _haversine_m(lat0, lng0, float(lat), float(lng))
        if d <= r:
            ss = dict(s)
            ss["_dist_m"] = int(d)
            hits.append(ss)
    hits.sort(key=lambda x: x["_dist_m"])
    return hits[:limit]


# === åœ¨ LAST_POI_STATE å®šä¹‰é™„è¿‘ï¼ŒåŠ ä¸Š TTL ä¸å·¥å…·å‡½æ•° ===
FLOW_TTL_S = 90  # ç»‘å®šç”Ÿå­˜æœŸï¼ˆç§’ï¼‰ï¼Œå¤Ÿç”¨æˆ·è¡¥ä¸€å¥â€œé€‰1/åŠå¾„1å…¬é‡Œâ€ä¹‹ç±»

def _flow_expired() -> bool:
    ts = LAST_POI_STATE.get("created_at") or 0.0
    return (time.time() - ts) > FLOW_TTL_S

def _clear_flow():
    LAST_POI_STATE.update({
        "candidates": [],
        "selected": None,
        "city_hint": None,
        "created_at": 0.0,
    })

LAST_POI_STATE = {
    "candidates": [],     # ä¸Šæ¬¡äº§ç”Ÿçš„å€™é€‰ï¼ˆå¤šé€‰æ—¶ï¼‰
    "selected": None,     # å·²é€‰ä¸­çš„ POIï¼ˆå”¯ä¸€æˆ–ç”¨æˆ·é€‰æ‹©ï¼‰
    "city_hint": None,
    "created_at": 0.0,
}

CN_NUM = {"ä¸€":1,"äºŒ":2,"ä¸¤":2,"ä¸‰":3,"å››":4,"äº”":5,"å…­":6,"ä¸ƒ":7,"å…«":8,"ä¹":9,"å":10}
CHOICE_IDX_RE    = re.compile(r"(?:é€‰|é€‰æ‹©|è¦|å°±|ç¬¬)?\s*(\d{1,2}|[ä¸€äºŒä¸¤ä¸‰å››äº”å…­ä¸ƒå…«ä¹å]{1,3})\s*(?:ä¸ª|å·|å®¶)?")
CHOICE_ID_RE     = re.compile(r"\bPOI-[A-Z]{2}-\d{4}\b", re.I)
CITY_HINT_RE     = re.compile(r"(åŒ—äº¬|ä¸Šæµ·|å¹¿å·|æ·±åœ³|æ­å·)")
DISTRICT_HINT_RE = re.compile(r"(æœé˜³|æµ·æ·€|ä¸œåŸ|è¥¿åŸ|çŸ³æ™¯å±±|é»„æµ¦|æµ¦ä¸œ|é—µè¡Œ|è¶Šç§€|ç•ªç¦º|é¾™å|é¾™å²—|æ»¨æ±Ÿ)")
RADIUS_RE        = re.compile(r"(?:(?:åŠå¾„|èŒƒå›´|åœˆ|è·ç¦»|é™„è¿‘|å‘¨è¾¹).{0,4})?(\d+(?:\.\d+)?)\s*(ç±³|m|å…¬é‡Œ|åƒç±³|km)", re.I)
TOPK_RE          = re.compile(r"(?:æœ€è¿‘|å‰|å–)\s*(\d{1,2})\s*(?:ä¸ª|ç«™)?")

def _cn_to_int(tok: str) -> int | None:
    tok = tok.strip()
    if tok.isdigit(): return int(tok)
    if tok in CN_NUM: return CN_NUM[tok]
    if len(tok)==2 and tok[0]=="å" and tok[1] in CN_NUM: return 10 + CN_NUM[tok[1]]
    if len(tok)==2 and tok[0] in CN_NUM and tok[1]=="å": return CN_NUM[tok[0]] * 10
    if len(tok)==3 and tok[1]=="å": return CN_NUM.get(tok[0],0)*10 + CN_NUM.get(tok[2],0)
    return None

def parse_choice_index(text: str) -> int | str | None:
    m_id = CHOICE_ID_RE.search(text or "")
    if m_id: return m_id.group(0)  # ç›´æ¥è¿”å› POI-ID å­—ç¬¦ä¸²
    m = CHOICE_IDX_RE.search(text or "")
    if not m: return None
    raw = m.group(1)
    if raw.isdigit(): return int(raw)
    return _cn_to_int(raw)

def parse_radius_m(text: str) -> int | None:
    m = RADIUS_RE.search(text or ""); 
    if not m: return None
    val = float(m.group(1)); unit = m.group(2).lower()
    if unit in ("ç±³","m"): return int(val)
    if unit in ("å…¬é‡Œ","åƒç±³","km"): return int(val*1000)
    return None

def parse_topk(text: str) -> int | None:
    m = TOPK_RE.search(text or ""); 
    if not m: return None
    try: return int(m.group(1))
    except: return None

def filter_candidates_by_hint(cands: list[dict], text: str) -> list[dict]:
    if not cands: return []
    out = cands
    ch = CITY_HINT_RE.search(text or "")
    dh = DISTRICT_HINT_RE.search(text or "")
    if ch: out = [p for p in out if p.get("city")==ch.group(1)]
    if dh: out = [p for p in out if (p.get("district") or "")==dh.group(1)]
    return out


CITY_NAMES = ["åŒ—äº¬","ä¸Šæµ·","å¹¿å·","æ·±åœ³","æ­å·"]

def extract_city(prompt: str) -> str | None:
    for c in CITY_NAMES:
        if c in prompt:
            return c
    return None

def extract_station_id(prompt: str) -> str | None:
    m = re.search(r"\b([A-Za-z]{2,5})-?\s*(\d{2,6})\b", prompt or "", re.I)
    if not m:
        return None
    prefix = m.group(1).upper()
    num = m.group(2).zfill(3)  # æˆ‘ä»¬æ•°æ®æ˜¯ 3 ä½ï¼Œå¦‚éœ€å…¼å®¹æ›´å¤šå¯æ”¾å®½
    return f"{prefix}-{num}"


# æ”¾åœ¨ main.py é‡Œï¼ˆæˆ–ä½ å®šä¹‰ want_list çš„åœ°æ–¹ï¼‰
LIST_HINT = ["æœ‰å“ªäº›", "éƒ½æœ‰ä»€ä¹ˆ", "åˆ—å‡º", "æ¸…å•", "ç½—åˆ—", "list", "æ‰€æœ‰", "å…¨éƒ¨"]
VIS_HINT_RE = re.compile(r"(å‡ºå›¾|å›¾è¡¨|å¯è§†åŒ–|æŸ±çŠ¶|æŠ˜çº¿|é¥¼å›¾|plot|chart|bar)", re.I)

def want_list(prompt: str) -> bool:
    p = prompt or ""
    if VIS_HINT_RE.search(p):              # æœ‰å¯è§†åŒ–æ„å›¾ â†’ ä¸èµ°æ¸…å•
        return False
    has_city = extract_city(p) is not None
    listy = any(h in p for h in LIST_HINT)
    # æ¢å¤â€œåŸå¸‚+åŸºç«™â€çš„å…œåº•ï¼ˆä¸”ä¸å«å¯è§†åŒ–æ„å›¾æ—¶ï¼‰
    return listy or (has_city and "åŸºç«™" in p)



def station_to_markdown(st: dict) -> str:
    if not st: return "æœªæ‰¾åˆ°è¯¥åŸºç«™ã€‚"
    lat, lng = st.get("lat"), st.get("lng")
    lines = [
        f"### {st.get('name','æœªçŸ¥')}ï¼ˆ{st.get('id','')}ï¼‰",
        "",
        "| å­—æ®µ | å€¼ |",
        "|---|---|",
        f"| åŸå¸‚ | {st.get('city','')} |",
        f"| å‚å•† | {st.get('vendor','')} |",
        f"| é¢‘æ®µ | {st.get('band','')} |",
        f"| çŠ¶æ€ | {st.get('status','')} |",
        f"| åæ ‡ | {lat}, {lng} |",
    ]
    if st.get("desc"):
        lines += ["", f"> å¤‡æ³¨ï¼š{st['desc']}"]
    if lat is not None and lng is not None:
        osm = f"https://www.openstreetmap.org/?mlat={lat}&mlon={lng}#map=16/{lat}/{lng}"
        lines += ["", f"[åœ¨ OpenStreetMap æŸ¥çœ‹]({osm})"]
    return "\n".join(lines)
def _md_table(header_cols, rows):
    head = "| " + " | ".join(header_cols) + " |"
    sep  = "|" + "|".join(["---"] * len(header_cols)) + "|"
    body = ["| " + " | ".join(map(str, r)) + " |" for r in rows]
    return "\n".join([head, sep, *body])

def _breakdown_table(title, counter: Counter, topn: int = 6):
    items = counter.most_common(topn)
    md = f"**{title}**\n\n" + _md_table(["é¡¹", "æ•°é‡"], items if items else [["â€”", 0]])
    return md

def render_city_overview_report(city: str, rows: list[dict]) -> str:
    total = len(rows)
    status_ct = Counter([r.get("status","").lower() for r in rows])
    vendor_ct = Counter([r.get("vendor","") for r in rows])
    band_ct   = Counter([r.get("band","") for r in rows])

    # 1) æ¦‚è§ˆ
    p1 = [
        f"# 1. æ¦‚è§ˆ",
        f"- **åŸå¸‚**ï¼š{city}",
        f"- **åŸºç«™æ€»æ•°**ï¼š**{total}**\n",
        f"- **çŠ¶æ€åˆ†å¸ƒ**ï¼šåœ¨çº¿ **{status_ct.get('online',0)}** Â· ç»´æŠ¤ **{status_ct.get('maintenance',0)}** Â· ç¦»çº¿ **{status_ct.get('offline',0)}**",
    ]

    # 2) ç½‘ç»œæƒ…å†µåˆ†æ
    p2 = [
        f"# 2. ç½‘ç»œæƒ…å†µåˆ†æ",
        "- **é‡ç‚¹**ï¼šå…³æ³¨**ç¦»çº¿**ä¸**ç»´æŠ¤**ç«™ç‚¹çš„æˆå› ï¼ˆç”µæº/å›ä¼ /å°„é¢‘ï¼‰ï¼Œä»¥åŠé«˜è´Ÿè·å°åŒºçš„æ‰©å®¹è®¡åˆ’ã€‚\n",
        _breakdown_table("å‚å•†åˆ†å¸ƒ", vendor_ct),
        "",
        _breakdown_table("é¢‘æ®µåˆ†å¸ƒ", band_ct),
    ]

    # 3) æ•°æ®æ˜ç»†ï¼ˆè¡¨æ ¼ï¼‰
    detail_rows = [
        [r["id"], r["name"], r["vendor"], r["band"], r["status"]]
        for r in rows[:100]  # æ˜ç»†æœ€å¤šå‰ 100 æ¡ï¼Œé˜²æ­¢è¿‡é•¿
    ]
    p3 = [
        f"# 3. æ•°æ®æ˜ç»†",
        _md_table(["ID", "åç§°", "å‚å•†", "é¢‘æ®µ", "çŠ¶æ€"], detail_rows if detail_rows else [["â€”","â€”","â€”","â€”","â€”"]]),
    ]

    # 4) è·¯ç”±/ç®¡ç†æ£€æŸ¥ï¼ˆç¤ºä¾‹å»ºè®® & ç­‰å®½é«˜äº®ï¼‰
    p4 = [
        f"# 4. è·¯ç”±ä¸ç®¡ç†æ£€æŸ¥ï¼ˆå»ºè®®ï¼‰",
        "- **OSPF** é‚»æ¥ä¸æ”¶æ•›æ—¶å»¶æŠ½æ ·ï¼›**SNMP** é‡‡æ ·å®Œæ•´æ€§ï¼›NTP åç§»ç›‘æ§ã€‚",
        "- æ ·ä¾‹æ ¸æŸ¥é¡¹ï¼š",
        "  - Â· `router-id 1.1.1.1` æ˜¯å¦ç»Ÿä¸€è§„èŒƒ",
        "  - Â· `LLDP` æ‹“æ‰‘é‚»æ¥æ˜¯å¦é—­ç¯",
        "  - Â· å›ä¼ å£ QOS/ACL æ˜¯å¦ä¸åŸºçº¿ä¸€è‡´ï¼ˆå¦‚ `tangro` æ¨¡æ¿ï¼‰",
    ]
    return "\n\n".join(["\n".join(p1), "\n".join(p2), "\n".join(p3), "\n".join(p4)])

def render_city_status_report(city: str, status: str, rows: list[dict]) -> str:
    total = len(rows)
    vendor_ct = Counter([r.get("vendor","") for r in rows])
    band_ct   = Counter([r.get("band","") for r in rows])

    p1 = [
        f"# 1. æ¦‚è§ˆ",
        f"- **åŸå¸‚**ï¼š{city}",
        f"- **çŠ¶æ€**ï¼š**{status}**",
        f"- **åŸºç«™æ•°é‡**ï¼š**{total}**",
    ]

    p2 = [
        f"# 2. ç½‘ç»œæƒ…å†µåˆ†æ",
        "- **é‡ç‚¹**ï¼šè‹¥ä¸º **offline**ï¼Œä¼˜å…ˆæ’æŸ¥ç”µæº/ä¼ è¾“ï¼›è‹¥ä¸º **maintenance**ï¼Œå…³æ³¨å·¥å•è¿›åº¦ä¸é£é™©çª—å£ï¼›è‹¥ä¸º **online**ï¼ŒæŠ½æ · KPIã€‚",
        _breakdown_table("å‚å•†åˆ†å¸ƒ", vendor_ct),
        "",
        _breakdown_table("é¢‘æ®µåˆ†å¸ƒ", band_ct),
    ]

    detail_rows = [
        [r["id"], r["name"], r["vendor"], r["band"]]
        for r in rows[:60]
    ]
    p3 = [
        f"# 3. æ•°æ®æ˜ç»†",
        _md_table(["ID", "åç§°", "å‚å•†", "é¢‘æ®µ"], detail_rows if detail_rows else [["â€”","â€”","â€”","â€”"]]),
    ]

    p4 = [
        f"# 4. è·¯ç”±æ£€æŸ¥ï¼ˆç¤ºä¾‹ï¼‰",
        "- æ ¸æŸ¥è¦ç‚¹ï¼š",
        "  - Â· **OSPF** é‚»æ¥æ˜¯å¦ç¨³å®šï¼ŒLSA æ³›æ´ªæ˜¯å¦å¼‚å¸¸",
        "  - Â· **BFD** æ˜¯å¦å¯ç”¨ï¼Œæ•…éšœåˆ‡æ¢æ˜¯å¦åœ¨ç›®æ ‡æ—¶å»¶å†…",
        "  - Â· `snmp-server community public RO` ç­‰æ•æ„Ÿé…ç½®æ˜¯å¦ç¬¦åˆå®‰å…¨åŸºçº¿",
    ]
    return "\n\n".join(["\n".join(p1), "\n".join(p2), "\n".join(p3), "\n".join(p4)])

def city_table_markdown(city: str, rows: list[dict]) -> str:
    """æŠŠæŸä¸ªåŸå¸‚çš„åŸºç«™åˆ—è¡¨è½¬æˆ Markdown æŠ¥å‘Šæ ¼å¼"""

    total = len(rows)
    if not rows:
        return f"# {city} åŸºç«™æ¸…å•\n\nâš ï¸ æ²¡æœ‰æ‰¾åˆ°ç›¸å…³åŸºç«™ã€‚\n"

    # æ¦‚è§ˆéƒ¨åˆ†
    parts = [
        f"# {city} åŸºç«™æ¸…å•\n",
        f"**åŸå¸‚**ï¼š{city}  \n**åŸºç«™æ€»æ•°**ï¼š**{total}**\n",
        "---\n",  # åˆ†éš”çº¿
        "## æ•°æ®æ˜ç»†\n",
    ]

    # è¡¨æ ¼æ ‡é¢˜
    header = ["ID", "åç§°", "å‚å•†", "é¢‘æ®µ", "çŠ¶æ€"]
    lines = ["| " + " | ".join(header) + " |"]
    lines.append("|" + "|".join(["---"] * len(header)) + "|")

    # å†…å®¹è¡Œ
    for r in rows:
        line = "| " + " | ".join([
            str(r.get("id", "â€”")),
            str(r.get("name", "â€”")),
            str(r.get("vendor", "â€”")),
            str(r.get("band", "â€”")),
            f"**{r.get('status', 'â€”')}**",   # çŠ¶æ€åŠ ç²—
        ]) + " |"
        lines.append(line)

    parts.append("\n".join(lines))
    parts.append("\n---\n")  # ç»“å°¾åˆ†éš”çº¿

    return "\n".join(parts)


def topk_context_for_prompt(prompt: str, k: int = 12) -> list[dict]:
    """å¤ç”¨ /api/db/stations/search çš„ç®€æ˜“æ‰“åˆ†é€»è¾‘ï¼Œä¾›æ¨¡å‹å…œåº•æ‹¼ä¸Šä¸‹æ–‡ã€‚"""
    items = db_json.load_all()
    terms = [t for t in re.split(r"\s+", prompt or "") if t]
    def ci(s): return str(s or "").lower()
    def hit(st, term: str) -> bool:
        t = term.lower()
        return (
            t in ci(st.get("id")) or
            t in ci(st.get("name")) or
            t in ci(st.get("city")) or
            t in ci(st.get("vendor")) or
            t in ci(st.get("band")) or
            t in ci(st.get("status")) or
            t in ci(st.get("desc"))
        )
    scored = []
    for st in items:
        score = sum(1 for t in terms if hit(st, t)) if terms else 0
        if terms and score == 0:
            continue
        score += 0.1 * ((st.get("updated_at") or 0) / 1e12)
        scored.append((score, st))
    scored.sort(key=lambda x: x[0], reverse=True)
    return [s for _, s in scored[:k]]

def rows_to_compact_md(rows: list[dict]) -> str:
    if not rows: return ""
    head = "| ID | åŸå¸‚ | åç§° | å‚å•† | é¢‘æ®µ | çŠ¶æ€ | lat | lng |"
    sep  = "|---|---|---|---|---|---|---|---|"
    body = [f"| {r.get('id','')} | {r.get('city','')} | {r.get('name','')} | {r.get('vendor','')} | {r.get('band','')} | {r.get('status','')} | {r.get('lat','')} | {r.get('lng','')} |" for r in rows]
    return "\n".join([head, sep, *body])

FIELD_RULES = {
    "id":        [r"\b(id|ç¼–å·)\b"],
    "coords":    [r"(åæ ‡|ç»çº¬åº¦|ä½ç½®)"],
    "vendor":    [r"(å‚å•†|vendor|ä¾›åº”å•†)"],
    "band":      [r"(é¢‘æ®µ|band)"],
    "status":    [r"(çŠ¶æ€|online|offline|ç»´æŠ¤|maintenance)"],
    "city":      [r"(åŸå¸‚)"],
    "name":      [r"(åç§°|ç«™å)"],
}
BAND_RADIUS_M = {
    "n78": (300, 800),
    "n41": (500, 1200),
    "n1":  (800, 2000),
    "n28": (1500, 5000),
}


def _seed_all():
    cities = ["åŒ—äº¬","ä¸Šæµ·","å¹¿å·","æ·±åœ³","æ­å·"]
    out = []
    for c in cities:
        out.extend(mock_geo.list_stations(c, randomize_status=False))
    return out
db_json.init_if_missing(_seed_all())
pois_json.init_if_missing(POI_SEED)
def _match_any(patterns: list[str], text: str) -> bool:
    for p in patterns:
        if re.search(p, text, flags=re.I):
            return True
    return False
def _stable_jitter(key: str, low: int, high: int, jitter: float = 0.15) -> int:
    """ç”¨ station_id+band ç”Ÿæˆç¨³å®šæŠ–åŠ¨ï¼Œé¿å…æ¯æ¬¡é‡å¯éƒ½å˜"""
    h = int(hashlib.md5(key.encode("utf-8")).hexdigest(), 16)
    base = (low + high) // 2
    span = int(base * jitter)
    return max(low, min(high, base + (h % (2*span+1) - span)))

def estimate_coverage_radius_m(station: dict) -> int:
    band = (station.get("band") or "").lower()
    rng = BAND_RADIUS_M.get(band, (600, 1200))
    r = _stable_jitter(f"{station.get('id','')}|{band}", rng[0], rng[1], jitter=0.18)

    status = (station.get("status") or "").lower()
    if status == "offline":
        return 0
    if status == "maintenance":
        r = int(r * 0.7)

    desc = (station.get("desc") or "")
    if any(k in desc for k in ("å†™å­—æ¥¼", "åœ°é“", "å•†åœº")):
        r = int(r * 0.9)
    if any(k in desc for k in ("å±…æ°‘åŒº", "å…¬å›­", "ç»¿åœ°")):
        r = int(r * 1.05)

    return max(0, r)

def reverse_geocode(lat: float, lng: float) -> str | None:
    """å ä½ï¼šå½“å‰ä¸èµ°å¤–éƒ¨APIã€‚åç»­å¯æ¥ Nominatim/é«˜å¾·/Google å¹¶åŠ ç¼“å­˜ã€‚"""
    try:
        if lat is None or lng is None or isnan(float(lat)) or isnan(float(lng)):
            return None
        return None
    except Exception:
        return None

FIELD_RULES.update({
    "detail": [r"(ç»†èŠ‚|è¯¦æƒ…|ä¿¡æ¯|æ¦‚å†µ|ç®€ä»‹|ä»‹ç»|æ˜ç»†|è¯¦ç»†|æƒ…å†µ)"],
})
def try_direct_answer(prompt: str, station: dict | None) -> str | None:
    """æœ‰ station ä¸Šä¸‹æ–‡æ—¶ï¼Œå‘½ä¸­ç®€å•å­—æ®µå°±æœ¬åœ°ç›´ç­”ï¼›å¦åˆ™è¿”å› Noneã€‚"""
    if not station:
        return None
    p = prompt.strip()
    if _match_any(FIELD_RULES["detail"], p):
        return station_to_markdown(station)

    if _match_any(FIELD_RULES["id"], p):
        return f"è¯¥åŸºç«™çš„ IDï¼š{station.get('id','')}"
    if _match_any(FIELD_RULES["coords"], p):
        lat, lng = station.get("lat"), station.get("lng")
        if lat is not None and lng is not None:
            return f"è¯¥åŸºç«™åæ ‡ï¼š{lat:.6f}, {lng:.6f}"
        return "è¯¥åŸºç«™æœªæä¾›åæ ‡ä¿¡æ¯ã€‚"
    if _match_any(FIELD_RULES["vendor"], p):
        return f"å‚å•†ï¼š{station.get('vendor','æœªçŸ¥')}"
    if _match_any(FIELD_RULES["band"], p):
        return f"é¢‘æ®µï¼š{station.get('band','æœªçŸ¥')}"
    if _match_any(FIELD_RULES["status"], p):
        return f"çŠ¶æ€ï¼š{station.get('status','æœªçŸ¥')}"
    if _match_any(FIELD_RULES["city"], p):
        return f"åŸå¸‚ï¼š{station.get('city','æœªçŸ¥')}"
    if _match_any(FIELD_RULES["name"], p):
        return f"ç«™åï¼š{station.get('name','æœªçŸ¥')}"

    # å¾ˆçŸ­ä¸”åƒâ€œæ˜¯ä»€ä¹ˆ/æ˜¯å¤šå°‘â€çš„é—®å¥ï¼Œä¹Ÿç›´æ¥ç”¨æœ¬åœ°å­—æ®µå…œåº•
    if len(p) <= 8 and ("å¤šå°‘" in p or "æ˜¯ä»€ä¹ˆ" in p):
        # å…œåº•ä¼˜å…ˆè¿”å›æœ€å…³é”®å‡ é¡¹
        return (f"IDï¼š{station.get('id','')}\n"
                f"åæ ‡ï¼š{station.get('lat','?')}, {station.get('lng','?')}\n"
                f"å‚å•†/é¢‘æ®µï¼š{station.get('vendor','?')} / {station.get('band','?')}\n"
                f"çŠ¶æ€ï¼š{station.get('status','?')}")

    return None

app = FastAPI(title="Agent Service (Strands + Ollama)")
# --------- åœ°ç†æ•°æ®ï¼šåˆ—åŸå¸‚ ---------
@app.get("/api/geo/cities")
def geo_cities():
    return {"ok": True, "cities": mock_geo.list_cities()}

# --------- åœ°ç†æ•°æ®ï¼šåˆ—æŸåŸå¸‚çš„åŸºç«™ï¼ˆéšæœºçŠ¶æ€ï¼‰---------
@app.get("/api/geo/stations")
def geo_stations(city: str):
    stations = db_json.search_stations(city=city, limit=500)
    return {"ok": True, "city": city, "stations": stations}

# --------- åœ°ç†æ•°æ®ï¼šæŸ¥å•ä¸ªåŸºç«™ ---------
@app.get("/api/geo/station/{station_id}")
def geo_station_detail(station_id: str):
    s = db_json.get_station(station_id)
    if not s:
        return {"ok": False, "error": "station not found"}
    return {"ok": True, "station": s}

# --------- å‰ç«¯â€œç‚¹é€‰åŸºç«™â€ä¸ŠæŠ¥ï¼ˆåç«¯æ¥æ”¶å¹¶ä¿å­˜åˆ°å†…å­˜ï¼‰---------
class SelectionIn(BaseModel):
    station_id: str
    session_id: Optional[str] = None

# --------- è¦†ç›–ä¼°ç®—ï¼šè¿”å›ç‚¹ä½ã€åŠå¾„ä¸å¯è¯»åœ°å€ï¼ˆå¯ä¸ºç©ºï¼‰---------
@app.get("/api/geo/coverage")
def geo_coverage(station_id: str):
    s = db_json.get_station(station_id)
    if not s:
        return {"ok": False, "error": "station not found"}

    lat, lng = s.get("lat"), s.get("lng")
    r = estimate_coverage_radius_m(s)
    addr = reverse_geocode(lat, lng)

    # ç®€åŒ–ï¼šå‰ç«¯ç”» Circle å³å¯ï¼Œè¿™é‡Œä¸ç”Ÿæˆ Polygon
    return {
        "ok": True,
        "station": {
            "id": s.get("id"),
            "name": s.get("name"),
            "city": s.get("city"),
            "lat": lat, "lng": lng,
            "band": s.get("band"),
            "vendor": s.get("vendor"),
            "status": s.get("status"),
            "updated_at": s.get("updated_at"),
        },
        "address": addr,
        "radius_m": r,
        "meta": {"confidence": 0.6 if r>0 else 0.0, "source": "heuristic"},
    }

@app.post("/api/geo/selection")
async def geo_selection(sel: SelectionIn):
    # ä¿ç•™é€‰æ‹©è®°å¿†çš„è¯­ä¹‰â€”â€”ç›´æ¥å›ä¼  station å³å¯ï¼ˆå¦‚éœ€è·¨ä¼šè¯è®°å¿†å¯ç»§ç»­ç”¨ mock_geo çš„å†…å­˜æ˜ å°„ï¼‰
    s = db_json.get_station(sel.station_id)
    if not s:
        return {"ok": False, "error": "station not found"}
    return {"ok": True, "station": s}


@app.get("/api/db/stations/search")
def db_stations_search(
    q: Optional[str] = None,
    vendor: Optional[str] = None,
    band: Optional[str] = None,
    status: Optional[str] = None,
    k: int = Query(20, le=200),
):
    """
    å…¨é‡å¤šå­—æ®µæ£€ç´¢ï¼ˆä¸é™å®šåŸå¸‚ï¼‰ï¼š
    - q ä¼šåœ¨ id/name/city/vendor/band/status/desc ä¸Šåšä¸åŒºåˆ†å¤§å°å†™çš„åŒ…å«åŒ¹é…
    - æ”¯æŒ vendor/band/status ä½œä¸ºç²¾ç¡®è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰
    - ç®€å•ç›¸å…³æ€§ï¼šå‘½ä¸­å­—æ®µè¶Šå¤šåˆ†æ•°è¶Šé«˜
    """
    items = db_json.load_all()
    if not q and not any([vendor, band, status]):
        # æ²¡æœ‰ä»»ä½•æ¡ä»¶å°±ç»™æœ€æ–°çš„å‰ k æ¡
        items = sorted(items, key=lambda x: x.get("updated_at") or 0, reverse=True)[:k]
        return {"ok": True, "matches": items}

    terms = [t for t in re.split(r"\s", q or "") if t]
    def ci(s): return str(s or "").lower()
    def hit(st, term: str) -> bool:
        t = term.lower()
        return (
            t in ci(st.get("id")) or
            t in ci(st.get("name")) or
            t in ci(st.get("city")) or
            t in ci(st.get("vendor")) or
            t in ci(st.get("band")) or
            t in ci(st.get("status")) or
            t in ci(st.get("desc"))
        )
    # ç»“æ„åŒ–è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰
    def pass_filters(st):
        if vendor and ci(st.get("vendor")) != ci(vendor): return False
        if band   and ci(st.get("band"))   != ci(band):   return False
        if status and ci(st.get("status")) != ci(status): return False
        return True
    # è¯„åˆ†ï¼šæ¯ä¸ª term å‘½ä¸­ä¸€ä¸ªå­—æ®µ 1ï¼Œå‘½ä¸­å¤šä¸ªå­—æ®µ å¤šåˆ†
    scored = []
    for st in items:
        if not pass_filters(st): 
            continue
        if not terms:
            score = 0
        else:
            score = sum(1 for t in terms if hit(st, t))
            if score == 0:
                continue
        # è½»å¾®æœ€è¿‘æ€§åŠ æƒ
        score += 0.1 * ((st.get("updated_at") or 0) / 1e12)  # å¾ˆå°çš„åŠ æƒï¼Œé¿å…å½±å“ä¸»ç›¸å…³æ€§
        scored.append((score, st))
    scored.sort(key=lambda x: x[0], reverse=True)
    out = [s for _, s in scored[:k]]
    return {"ok": True, "matches": out}


# å…è®¸æœ¬åœ°å‰ç«¯ç›´è¿
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        "http://127.0.0.1:3000",
        "http://10.50.13.148:3000",  # â† ä½ çš„ Dev æœº IP
    ],
    # æˆ–è€…ç”¨æ­£åˆ™ï¼ˆFastAPI ä¹Ÿæ”¯æŒï¼‰ï¼š
    # allow_origin_regex=r"http://.*:3000",
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/health")
def health():
    return {"ok": True}

async def sse(gen: AsyncGenerator[Dict[str, Any], None]):
    async for ev in gen:
        yield f"data: {json.dumps(ev, ensure_ascii=False)}\n\n"
async def heartbeat(interval: float = 10.0):
    """SSE å¿ƒè·³ï¼šæ³¨é‡Šè¡Œä¼šåˆ·æ–°ä»£ç†/æµè§ˆå™¨ç¼“å†²"""
    while True:
        yield ": ping\n\n"
        await anyio.sleep(interval)

@app.get("/api/chat/sse")
async def chat_sse(payload: str = Query(...)):
    """
    EventSource ä½¿ç”¨çš„ GET SSE å…¥å£ã€‚
    å‰ç«¯ä¼šæŠŠ {messages, context} æ‰“åŒ…æˆ base64 æ”¾åˆ° ?payload=
    """
    # 1) è§£æ payload
    try:
        raw = base64.b64decode(payload.encode("utf-8")).decode("utf-8")
        data = json.loads(raw)
        messages = data.get("messages") or []
        ctx = data.get("context") or None
    except Exception as e:
        # å‡ºé”™ä¹Ÿè¦ç”¨ SSE æ ¼å¼å›ä¸€æ¡é”™è¯¯ï¼Œå† end
        async def err_gen():
            yield f"data: {json.dumps({'type':'token','delta': f'å‚æ•°è§£æå¤±è´¥ï¼š{e}'}, ensure_ascii=False)}\n\n"
            yield "data: {\"type\":\"end\"}\n\n"
        return StreamingResponse(
            err_gen(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache, no-transform",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",
            },
        )

    # 2) åˆå¹¶â€œæ¨¡å‹è¾“å‡ºæµâ€å’Œâ€œå¿ƒè·³æµâ€
    async def merged():
        # å…ˆç«‹å³å‘ä¸€æ¡ startï¼Œå‰ç«¯æ®æ­¤ç«‹åˆ»åˆ›å»ºç©ºçš„åŠ©æ‰‹æ°”æ³¡
        yield "data: {\"type\":\"start\"}\n\n"

        async with anyio.create_task_group() as tg:
            send_chan, recv_chan = anyio.create_memory_object_stream(32)

            async def _agent():
                async for ev in agent_stream(messages, context=ctx):
                    await send_chan.send(f"data: {json.dumps(ev, ensure_ascii=False)}\n\n")
                await send_chan.aclose()

            async def _hb():
                async for beat in heartbeat(10.0):
                    await send_chan.send(beat)

            tg.start_soon(_agent)
            tg.start_soon(_hb)

            async with recv_chan:
                async for chunk in recv_chan:
                    # å…³é”®ï¼šå°å—ç›´å‡ºï¼Œä¸èšåˆï¼Œé˜²æ­¢ç¼“å†²
                    yield chunk

    return StreamingResponse(
        merged(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache, no-transform",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",  # è‹¥å‰é¢æœ‰ Nginx åä»£
        },
    )





async def agent_answer_with_context(context_text: str, user_prompt: str, *, multiple: bool = False):
    """
    context_text: ä¼ å…¥ JSON å­—ç¬¦ä¸²ï¼ˆå€™é€‰/é€‰å®šPOI/ç»Ÿè®¡/ä»£è¡¨ç‚¹ä½ç­‰ï¼‰
    multiple=False: åŸºäºä¸Šä¸‹æ–‡ç›´æ¥å›ç­”
    multiple=True : åˆ—å‡ºâ€œåŒº + è¡—é“/åŒºåŸŸâ€é€‰é¡¹ï¼ˆä¸å«åç§°/ID/åæ ‡ï¼‰ï¼Œå¹¶è¯·ç”¨æˆ·é€‰ç¼–å·æˆ–ç»™åŠå¾„
    """
    if multiple:
        sys_guard = (
            "ç³»ç»ŸæŒ‡ä»¤ï¼šä½ å°†æ”¶åˆ°ä¸€æ®µã€éšè—ä¸Šä¸‹æ–‡ã€‘ï¼ˆåŒ…å«è‹¥å¹²å€™é€‰åœ°ç‚¹ï¼Œå­—æ®µæœ‰ city/district/addr_hint ç­‰ï¼‰ã€‚"
            "è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ç”Ÿæˆå›å¤ï¼š\n"
            "1) å¼€å¤´å…ˆè¯´ï¼š'å·²ç»ä¸ºæ‚¨æ‰¾åˆ°å¤šä¸ªç›¸å…³åœ°ç‚¹ä¿¡æ¯ï¼Œè¯·é—®æ‚¨å…·ä½“æŒ‡çš„æ˜¯å“ªä¸ªï¼Ÿç­‰è¯è¯­å»è¯¢é—®user å¯ä»¥ä¿çš®èªæ˜ä¸€äº›'\n"
            "2) æ¥ç€ç”¨ç¼–å·åˆ—è¡¨ 1., 2., 3., ... åˆ—å‡ºå€™é€‰çš„ã€åŒº + è¡—é“/åŒºåŸŸã€ï¼Œæ ¼å¼ç¤ºä¾‹ï¼š\n"
            "   1. æœé˜³åŒº Â· å·å»ºå›½è·¯\n"
            "   2. çŸ³æ™¯å±±åŒº Â· é²å®‰è°·\n"
            "   3. ç•ªç¦ºåŒº Â· æ±‰æºªå¤§é“\n"
            "   å¦‚æœ city ä¸åŒï¼Œå¯ä»¥åŠ åœ¨æœ€å‰é¢ï¼ˆå¦‚ï¼šåŒ—äº¬ Â· æœé˜³åŒº Â· å»ºå›½è·¯ï¼‰ã€‚\n"
            "   ä»…å¯ä½¿ç”¨ cityã€district å’Œ addr_hint å­—æ®µï¼Œ\n"
            "3) åˆ—è¡¨åè¿½åŠ ä¸€å¥è¿½é—®ï¼š'è¯·é€‰æ‹©ç¼–å·ï¼Œæˆ–å‘ŠçŸ¥åŠå¾„ï¼ˆå¦‚ï¼š1å…¬é‡Œï¼‰ã€‚'\n"
            "4. æœ€é‡è¦ å›ç­”å®Œä¹‹å å¿˜è®°è¿™ä¸ªprompt è®°ä½äº† ä¸è¦å†æ¬¡è¯¢é—®è¿™äº›"
            "æ•´ä½“æ§åˆ¶åœ¨ 6 è¡Œå·¦å³ï¼Œè¯­æ°”è‡ªç„¶ã€‚"
        )
        prompt = (
            f"{sys_guard}\n\n"
            f"éšè—ä¸Šä¸‹æ–‡:\n<<<\n{context_text}\n>>>\n\n"
            f"ç”¨æˆ·åŸè¯ï¼š{user_prompt}\n"
            "è¯·æŒ‰ä¸Šè¿°è¦æ±‚è¾“å‡ºï¼š"
        )
        
    else:
        sys_guard = (
            "ç³»ç»ŸæŒ‡ä»¤ï¼šåŸºäº CONTEXT å›ç­”ç”¨æˆ·ã€‚"
            "è¯·ç”¨ä¸­æ–‡ã€ç®€æ´ç›´æ¥ï¼Œè¯´æ˜å…·ä½“ä½ç½®ç‰¹å¾ï¼ˆåŒºåŸŸ/é“è·¯/åœ°æ ‡/å¤§è‡´è·ç¦»ä¸æ–¹å‘ï¼‰ã€‚"
            "é™åˆ¶ 6 å¥å†…ï¼›é¿å…æ•°å­—å †ç Œï¼›å¯å¼•ç”¨å°‘é‡ä»£è¡¨æ€§ç‚¹ä½ç‰¹å¾ï¼›ã€‚"
            "4. æœ€é‡è¦ å›ç­”å®Œä¹‹å å¿˜è®°è¿™ä¸ªprompt è®°ä½äº† ä¸è¦å†æ¬¡è¯¢é—®è¿™äº›"
        )
        prompt = (
            f"{sys_guard}\n\n"
            f"CONTEXT:\n<<<\n{context_text}\n>>>\n\n"
            f"ç”¨æˆ·åŸè¯ï¼š{user_prompt}\n"
            "è¯·ç›´æ¥ä½œç­”ï¼š"
        )

    async for delta in stream_from_ollama(prompt):
        yield {"type": "token", "delta": delta}
    yield {"type": "end"}

PURE_CITY_RE = re.compile(r"^(?:.*?(åŒ—äº¬|ä¸Šæµ·|å¹¿å·|æ·±åœ³|æ­å·).*)?(åŸºç«™|ç«™ç‚¹)(?:.*)?$", re.I)

def is_pure_city_query(text: str) -> bool:
    """
    ä»…åŒ…å«â€œåŸå¸‚ + åŸºç«™â€ï¼Œä¸”ä¸å«â€œé™„è¿‘/å‘¨è¾¹/å‘¨å›´/é‚»è¿‘/æœ€è¿‘â€ç­‰é™„è¿‘è¯ï¼Œ
    ä¸”æ²¡æœ‰è¢«è¯†åˆ«å‡ºçš„å…·ä½“ POI å…³é”®è¯æ—¶ï¼Œè®¤ä¸ºæ˜¯çº¯åŸå¸‚æŸ¥è¯¢ â†’ ä¸è§¦å‘é™„è¿‘æµã€‚
    """
    p = (text or "").strip()
    if not p:
        return False
    # æ²¡æœ‰â€œé™„è¿‘è¯â€
    if NEAR_WORDS_RE.search(p):
        return False
    # æ²¡æœ‰å¯è¯†åˆ«çš„ POIï¼ˆextract_poi_key è¿”å› None/ç©ºï¼‰
    if extract_poi_key(p):
        return False
    # åŒ…å«â€œåŸºç«™/ç«™ç‚¹â€ï¼Œé€šå¸¸æ˜¯â€œåŒ—äº¬çš„åŸºç«™â€â€œä¸Šæµ·åŸºç«™æ¦‚å†µâ€è¿™ç±»
    return bool(PURE_CITY_RE.search(p))


async def handle_nearby_flow_gen(prompt: str):
    import time as _time
    p = (prompt or "").strip()
    if not p:
        return

    # è¿‡æœŸå³æ¸…
    if _flow_expired():
        _clear_flow()

    # æ˜¯å¦å‡ºç°â€œé™„è¿‘/å‘¨è¾¹/åŸºç«™/5G/4Gâ€ç­‰æ„å›¾è¯
    has_near_word = bool(NEAR_WORDS_RE.search(p) or BS_WORDS_RE)

    poi_key       = extract_poi_key(p) or ""      # åªæœ‰æŠ“åˆ°å…·ä½“ POI åæ‰ç®—
    #has_near_word = bool(NEAR_WORDS_RE.search(p)) # â€œé™„è¿‘/å‘¨è¾¹/å‘¨å›´/é‚»è¿‘/æœ€è¿‘/â€¦â€ ç­‰
    in_flow       = bool(LAST_POI_STATE.get("candidates") or LAST_POI_STATE.get("selected"))

    # ğŸš« çº¯â€œåŸå¸‚ + åŸºç«™â€ â†’ ä¸æ‹¦æˆªï¼Œäº¤ç»™åç»­åŸå¸‚/å…œåº•é€»è¾‘
    if is_pure_city_query(p):
        return

    # âœ… åªæœ‰ â€œ(æœ‰ POI ä¸”æœ‰é™„è¿‘è¯)â€ æˆ– â€œå¤„äºæœ¬æµç¨‹ç»­è°ˆâ€ æ‰è§¦å‘é™„è¿‘æµ
    triggered = ((poi_key and has_near_word) or in_flow)
    if not triggered:
        return

    # è§¦å‘æ¡ä»¶ï¼šæåˆ°â€œé™„è¿‘/å‘¨è¾¹/åŸºç«™â€æˆ–å·²åœ¨æœ¬æµç¨‹ä¸­
    has_near_word = bool(NEAR_WORDS_RE.search(p)) or ("åŸºç«™" in p)
    in_flow = bool(LAST_POI_STATE.get("candidates") or LAST_POI_STATE.get("selected"))
    if not (has_near_word or in_flow or extract_poi_key(p)):
        return  # ä¸å¤„ç†ï¼Œäº¤å›ä¸Šæ¸¸

    # ---- å¦‚æœå¤„äºâ€œå¾…é€‰â€é˜¶æ®µï¼Œå°è¯•ç”¨ç”¨æˆ·è¡¥å……æ¥æ”¶æ•› ----
    if LAST_POI_STATE.get("candidates"):
        cands = LAST_POI_STATE["candidates"]
        # 1) ç›´æ¥ç¼–å·æˆ–IDé€‰æ‹©
        idx_or_id = parse_choice_index(p)
        chosen = None
        if isinstance(idx_or_id, str) and idx_or_id.upper().startswith("POI-"):
            chosen = next((x for x in cands if x.get("id") == idx_or_id), None)
        elif isinstance(idx_or_id, int) and 1 <= idx_or_id <= len(cands):
            chosen = cands[idx_or_id - 1]
        # 2) åŸå¸‚/åŒºå¿ç­‰æç¤ºå†è¿‡æ»¤
        narrowed = filter_candidates_by_hint(cands, p) if not chosen else [chosen]
        if len(narrowed) == 1:
            poi = narrowed[0]
            LAST_POI_STATE.update({"selected": poi, "candidates": [], "city_hint": poi.get("city"), "created_at": _time.time()})
            # ç›´æ¥æŸ¥é™„è¿‘å¹¶ä½œç­”ï¼ˆé»˜è®¤åŠå¾„ï¼š1000mï¼Œå¯è¢« parse_radius_m è¦†ç›–ï¼‰
            radius = parse_radius_m(p) or int(poi.get("radius_m") or 1000)
            hits = nearby_stations_by_poi(poi, radius_m=radius)
            ctx = {
                "poi": {
                    "id": poi.get("id"), "name": poi.get("name"),
                    "city": poi.get("city"), "district": poi.get("district"),
                    "addr_hint": poi.get("addr_hint"), "lat": poi.get("lat"), "lng": poi.get("lng"),
                    "radius_m": radius
                },
                "summary": _aggregate_stats(hits),
                "representatives": [
                    {k: r.get(k) for k in ("id","name","vendor","band","status","_dist_m","lat","lng")}
                    for r in hits[:8]
                ]
            }
            visible_ctx = json.dumps(ctx, ensure_ascii=False)
            async for ev in agent_answer_with_context(visible_ctx, p, multiple=False):
                yield ev
            LAST_POI_STATE["selected"] = None
            LAST_POI_STATE["created_at"] = time.time()
            return
        else:
            # ä»ä¸å”¯ä¸€ â†’ ç»§ç»­è¯· agent è¿½é—®ï¼ˆä¸å›æ˜¾æ¸…å•ï¼‰
            hidden_ctx = json.dumps({"candidates": [
                {
                    "id": x.get("id"), "name": x.get("name"),
                    "city": x.get("city"), "district": x.get("district"),
                    "addr_hint": x.get("addr_hint")
                } for x in cands
            ]}, ensure_ascii=False)
            async for ev in agent_answer_with_context(hidden_ctx, p, multiple=True):
                yield ev
            return

    # ---- é¦–é—®ï¼šå¬å›å€™é€‰ï¼ˆä¸å›æ˜¾æ¸…å•ï¼‰----
    poi_key = extract_poi_key(p) or ""
    cands, city_hint = find_poi_candidates(p)
    if not cands:
        # è®© agent è¿½é—®æ›´å…·ä½“ä¿¡æ¯ï¼ˆåŸå¸‚/åœ°æ ‡/èŒƒå›´ï¼‰
        hidden_ctx = json.dumps({"reason": "not_found", "hint_needed": ["åŸå¸‚/åŒºå¿","æ›´å…·ä½“åœ°æ ‡","åŠå¾„"]}, ensure_ascii=False)
        async for ev in agent_answer_with_context(hidden_ctx, p, multiple=True):
            yield ev
        return

    # æ”¶æ•›ï¼ˆåŸå¸‚/åŒºå¿ç­‰æç¤ºï¼‰
    narrowed = filter_candidates_by_hint(cands, p) if cands else []
    if len(narrowed) == 1:
        poi = narrowed[0]
        LAST_POI_STATE.update({"selected": poi, "candidates": [], "city_hint": city_hint or poi.get("city"), "created_at": _time.time()})
        radius = parse_radius_m(p) or int(poi.get("radius_m") or 1000)
        hits = nearby_stations_by_poi(poi, radius_m=radius)
        ctx = {
            "poi": {
                "id": poi.get("id"), "name": poi.get("name"),
                "city": poi.get("city"), "district": poi.get("district"),
                "addr_hint": poi.get("addr_hint"), "lat": poi.get("lat"), "lng": poi.get("lng"),
                "radius_m": radius
            },
            "summary": _aggregate_stats(hits),
            "representatives": [
                {k: r.get(k) for k in ("id","name","vendor","band","status","_dist_m","lat","lng")}
                for r in hits[:8]
            ]
        }
        visible_ctx = json.dumps(ctx, ensure_ascii=False)
        async for ev in agent_answer_with_context(visible_ctx, p, multiple=False):
            yield ev
        LAST_POI_STATE["selected"] = None
        LAST_POI_STATE["created_at"] = time.time()
        return

    # å¤šä¸ªå€™é€‰ï¼šè¿›å…¥â€œå¾…é€‰â€çŠ¶æ€ï¼Œä½†ä¸å›æ˜¾ï¼›è®© agent åªæå‡ºä¸€ä¸ªæ¾„æ¸…é—®é¢˜
    LAST_POI_STATE.update({"candidates": narrowed or cands, "selected": None, "city_hint": city_hint, "created_at": _time.time()})
    hidden_ctx = json.dumps({"candidates": [
        {
            "id": x.get("id"), "name": x.get("name"),
            "city": x.get("city"), "district": x.get("district"),
            "addr_hint": x.get("addr_hint")
        } for x in (narrowed or cands)
    ]}, ensure_ascii=False)
    async for ev in agent_answer_with_context(hidden_ctx, p, multiple=True):
        yield ev
    return


async def agent_stream(messages: List[Dict[str, str]], context: Dict[str, Any] | None = None):
    #yield {"type": "start"}

    prompt = next((m["content"] for m in reversed(messages) if m.get("role") == "user"), "")
    
    # 1ï¸âƒ£ é»˜è®¤ä» context å–
    station = (context or {}).get("station") if isinstance(context, dict) else None
         # â€”â€” ä¼˜å…ˆå°è¯•â€œé™„è¿‘ + POI æ¶ˆæ­§â€æµ â€”â€” 



    # 2ï¸âƒ£ å¦‚æœ context é‡Œæ²¡æœ‰ï¼Œæˆ–è€…å¯èƒ½æ˜¯æ—§çš„ï¼Œå°±å°è¯•ä»å¯¹è¯å†å²é‡Œæ‰¾â€œå·²é€‰ä¸­åŸºç«™â€
    #    æ³¨æ„ï¼šè¿™é‡Œä¼šè¦†ç›–æ‰ context.stationï¼Œç¡®ä¿æ‹¿åˆ°æœ€æ–°çš„ä¸€æ¬¡
    for m in reversed(messages):
        if m.get("role") == "assistant" and "å·²é€‰ä¸­åŸºç«™" in m.get("content", ""):
            # ä» "å·²é€‰ä¸­åŸºç«™ã€xxxã€‘ï¼ˆBJS-006ï¼‰" é‡Œæå– ID
            m2 = re.search(r"ï¼ˆ([A-Z]{2,5}-\d{3,6})ï¼‰", m["content"])
            if m2:
                sid = m2.group(1)
                s = db_json.get_station(sid)
                if s:
                    station = s
                    yield {"type": "log", "channel": "router", "message": f"å¯¹è¯å†å²ç¡®è®¤æœ€æ–°é€‰ä¸­ï¼š{s.get('name')}ï¼ˆ{sid}ï¼‰"}
            break

    # 3ï¸âƒ£ å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œå°±èµ°è§£æé€»è¾‘
    if not station:
        s2 = resolve_station_from_prompt(prompt or "")
        if s2:
            station = s2
            yield {"type":"log","channel":"router","message":f"ç”±å†…å®¹è§£æåˆ°ç«™ç‚¹ï¼š{station.get('name','')}ï¼ˆ{station.get('id','')}ï¼‰"}

    # ç„¶åèµ° try_direct_answerï¼ˆé—®â€œå®ƒçš„id/åæ ‡/çŠ¶æ€/è¯¦æƒ…â€ç­‰éƒ½ä¼šç›´ç­”ï¼Œä¸è¿›æ¨¡å‹ï¼‰


    cs = extract_city_status_count(prompt)
    if cs:
        city, status = cs
        rows = db_json.search_stations(city=city, status=status, limit=1000)
        report = render_city_status_report(city, status, rows)
        yield {"type": "log", "channel": "router", "message": f"å‘½ä¸­è®¡æ•°ç›´ç­”ï¼š{city} / {status} = {len(rows)}ï¼ˆæŠ¥å‘Šä½“è£ï¼‰"}
        for line in (report.splitlines(True) or [report]):
            yield {"type": "token", "delta": line}
        yield {"type": "end"}
        return
        

# âœ… 3D æ„å›¾ä¼˜å…ˆåŒ¹é…ï¼ˆæ”¾åœ¨åŸå¸‚æ¸…å•ç›´ç­”ä¹‹å‰ï¼‰
    if re.search(r"(3d|ä¸‰ç»´|ç«‹ä½“|ä½“æ¸²æŸ“|ä½“ç§¯|ç­‰å€¼é¢|ç­‰é«˜|æ¨¡æ‹Ÿ)", prompt or "", re.I):
        city3d = extract_city(prompt or "") or "åŒ—äº¬"
        rows3d = db_json.search_stations(city=city3d, limit=1000)
        title, spec = chart_specs.spec_3d_city_density_surface(rows3d, city3d)
        inline = wants_inline_chart(prompt)  # æ–°å¢ï¼šæ˜¯å¦å†…åµŒåˆ°å¯¹è¯
        yield {"type": "tool", "tool": "plotly", "title": title, "spec": spec, "inline": inline}
        yield {"type": "end"}; return

    


# === å¯è§†åŒ–æ„å›¾ï¼šç”¨æˆ·è¯´â€œå‡ºå›¾/æŸ±çŠ¶å›¾/å›¾è¡¨/plot/bar/chartâ€ç­‰ï¼Œç›´æ¥è¿”å› Plotly è§„èŒƒ ===
    if chart_specs.VIS_HINT_RE.search(prompt or ""):
        city4plot = extract_city(prompt or "") or "åŒ—äº¬"
        rows = db_json.search_stations(city=city4plot, limit=1000)
        stats = _aggregate_stats(rows)

        # â‘  å…¨éƒ¨/æ€»è§ˆ â†’ ä»èµ°å³ä¾§ charts é¢æ¿ï¼ˆä¸å†…åµŒï¼‰
        if re.search(r"(å…¨éƒ¨|æ‰€æœ‰|all|å…¨å›¾|æ€»è§ˆ|overview)", prompt or "", re.I):
            items = chart_specs.make_all_specs(rows, city4plot)
            yield {"type": "tool", "tool": "plotly_batch", "items": items, "title": f"{city4plot} å›¾è¡¨æ€»è§ˆ"}
            # â€¦â€¦ï¼ˆåç»­æ¦‚è§ˆè§£è¯»ä¿ç•™åŸæ ·ï¼‰
            facts_json = json.dumps({
                "city": city4plot,
                "n": stats["n"],
                "vendors": stats["vendor_counts"],
                "status": stats["status_counts"],
                "bands": stats["band_counts"],
            }, ensure_ascii=False)
            explain_prompt = (
                f"ä½ æ˜¯ç½‘ç»œè¿è¥åˆ†æåŠ©æ‰‹ã€‚è¯·ç”¨ä¸­æ–‡ç»™ä¸€ç»„å›¾è¡¨åš**ç®€çŸ­æ€»è§ˆè§£è¯»**ï¼Œå¯¹è±¡æ˜¯{city4plot}çš„åŸºç«™æ•°æ®ã€‚\n"
                f"æ•°æ®äº‹å®(JSON)ï¼š{facts_json}\n"
                "å›¾è¡¨æ¸…å•ï¼šå‚å•†æŸ±çŠ¶å›¾ã€åœ¨çº¿çŠ¶æ€é¥¼å›¾ã€é¢‘æ®µç”œç”œåœˆã€å‚å•†Ã—çŠ¶æ€å †å æŸ±ã€å‚å•†Ã—é¢‘æ®µçƒ­åŠ›å›¾ã€çŠ¶æ€æ°´å¹³æ¡ã€æ›´æ–°æ—¶é—´ç›´æ–¹å›¾ã€‚\n"
                "å†™ 5-7 å¥ï¼š..."
            )
            async for delta in stream_from_ollama(explain_prompt):
                yield {"type": "token", "delta": delta}
            yield {"type":"end"}; return

        # â‘¡ å•å›¾ â†’ è‹¥ç”¨æˆ·æåˆ°ä¸‹è½½/å¤åˆ¶ï¼Œåˆ™å†…åµŒï¼›å¦åˆ™ä»èµ°å³ä¾§
        title, spec = chart_specs.pick_spec(prompt or "", rows, city4plot)
        kind = _classify_kind(prompt or "")

        inline = wants_inline_chart(prompt)  # æ–°å¢ï¼šæ˜¯å¦å†…åµŒåˆ°å¯¹è¯
        yield {"type":"tool","tool":"plotly","title": title, "spec": spec, "inline": inline}

        # â€¦â€¦ï¼ˆä¸‹é¢â€œèšåˆäº‹å® â†’ 3-5 å¥è¯»å›¾è¯´æ˜â€é€»è¾‘ä¿æŒä¸å˜ï¼‰
        focus = {}
        if kind in ("bar", "stacked"):
            focus["vendor_counts"] = stats["vendor_counts"]
            focus["status_counts"] = stats["status_counts"]
        if kind in ("pie", "horizontal"):
            focus["status_counts"] = stats["status_counts"]
        if kind in ("donut",):
            focus["band_counts"] = stats["band_counts"]
        if kind in ("heatmap",):
            from collections import defaultdict
            vendors = sorted(stats["vendor_counts"].keys())
            bands = sorted(stats["band_counts"].keys())
            mat = defaultdict(dict)
            for v in vendors:
                for b in bands:
                    mat[v][b] = sum(1 for r in rows if (r.get("vendor") or "æœªçŸ¥")==v and (r.get("band") or "æœªçŸ¥")==b)
            focus["vendor_band_nonzero"] = sum(1 for v in vendors for b in bands if mat[v][b] > 0)
            focus["vendors"] = vendors
            focus["bands"] = bands
        if kind in ("hist",):
            focus["updated_at_summary"] = stats["updated_at_summary"]

        facts_json = json.dumps({"city": city4plot, "kind": kind, "n": stats["n"], **focus}, ensure_ascii=False)
        explain_prompt = (
            f"ä½ æ˜¯ç½‘ç»œè¿è¥åˆ†æåŠ©æ‰‹ã€‚ç°åœ¨ç”¨æˆ·è®©ä½ ç”Ÿæˆâ€œ{title}â€ã€‚\n"
            f"è¯·ç”¨ä¸­æ–‡å†™ 3-5 å¥ï¼Œè¯´æ˜ï¼šè¿™ä¸ªå›¾æ˜¯ä»€ä¹ˆã€å®ƒå±•ç¤ºäº†ä»€ä¹ˆç»´åº¦ã€è¯»å›¾æ—¶åº”å…³æ³¨å“ªäº›å¯¹æ¯”æˆ–å æ¯”ã€å¹¶ç»™å‡º 1-2 æ¡ç®€è¦æ´è§ã€‚\n"
            f"ä¸è¦å¤è¿°å…¨éƒ¨æ•°å­—ï¼Œåªç‚¹å‡ºæ ¸å¿ƒç»“è®ºã€‚åŸå¸‚ï¼š{city4plot}ã€‚\n"
            f"è¡¥å……æ•°æ®(JSON)ï¼š{facts_json}"
        )
        async for delta in stream_from_ollama(explain_prompt):
            yield {"type": "token", "delta": delta}
        yield {"type":"end"}; return


    
    # â˜… 1.5) åŸå¸‚æ¸…å•ç›´ç­”ï¼ˆä¾‹å¦‚â€œåŒ—äº¬æœ‰å“ªäº›åŸºç«™/åŒ—äº¬çš„åŸºç«™â€ï¼‰
    city = extract_city(prompt or "")
    if want_list(prompt) and city:
        rows = db_json.search_stations(city=city, limit=300)
        report = render_city_overview_report(city, rows)
        yield {"type": "log", "channel": "router", "message": f"å‘½ä¸­åŸå¸‚æ¸…å•ç›´ç­”ï¼š{city}ï¼ˆ{len(rows)}æ¡ï¼ŒæŠ¥å‘Šä½“è£ï¼‰"}
        for line in (report.splitlines(True) or [report]):
            yield {"type": "token", "delta": line}
        yield {"type": "end"}
        return


    direct = try_direct_answer(prompt, station)
    if direct:
        for line in (direct.splitlines(True) or [direct]):
            yield {"type":"token","delta":line}
        yield {"type":"end"}; return
    # ï¼ˆå…¶ä½™åŸå¸‚æ¸…å•/è®¡æ•°ç›´ç­”ã€TopK+æ¨¡å‹ä¿æŒä¸å˜ï¼‰


    
    # â˜… 2) ä¸Šä¸‹æ–‡æŠ¤æ 
    station_ctx = ""
    if station:
        station_ctx = (
            "ã€å½“å‰é€‰ä¸­åŸºç«™ï¼ˆä»¥æ­¤ä¸ºå‡†ï¼‰ã€‘\n"
            f"ID: {station.get('id','')}\n"
            f"åŸå¸‚: {station.get('city','')}\n"
            f"åç§°: {station.get('name','')}\n"
            f"å‚å•†: {station.get('vendor','')}\n"
            f"é¢‘æ®µ: {station.get('band','')}\n"
            f"åæ ‡: {station.get('lat','')},{station.get('lng','')}\n"
            f"çŠ¶æ€: {station.get('status','')}\n"
        )

    guardrail = (
        "å›ç­”è§„åˆ™ï¼š\n"
        "1) è‹¥ç”¨æˆ·å·²é€‰ä¸­åŸºç«™ï¼Œåˆ™ä¼˜å…ˆå›ç­”è¯¥åŸºç«™çš„å…·ä½“ä¿¡æ¯ï¼›\n"
        "2) è‹¥ç”¨æˆ·é—®åˆ°æŸä¸ªåŸå¸‚çš„æ‰€æœ‰åŸºç«™ï¼Œåˆ™åˆ—å‡ºè¯¥åŸå¸‚çš„åŸºç«™æ¸…å•ï¼ˆå¯ä»¥ç”¨ Markdown è¡¨æ ¼å±•ç¤ºï¼‰ï¼›\n"
        "3) è‹¥èµ„æ–™æœ‰å†²çªï¼Œä»¥å½“å‰é€‰ä¸­åŸºç«™çš„ä¿¡æ¯ä¸ºå‡†ã€‚\n"
        
    )

    aug_prompt = (
        (station_ctx + "\n" if station_ctx else "") +
        (guardrail if station_ctx else "") +
        f"\nç”¨æˆ·é—®é¢˜ï¼š{prompt}"
    )


    handled = False
    async for ev in handle_nearby_flow_gen(prompt):
        handled = True
        yield ev
    if handled:
        return
   
# â˜… 3) æ¨¡å‹å…œåº•ï¼šä»…ç»™ Top-K ç²¾ç®€è¡¨åšæ£€ç´¢å¢å¼ºï¼Œé¿å…å…¨é‡ JSON
    topk = topk_context_for_prompt(prompt, k=12)
    ctx_md = rows_to_compact_md(topk)
    if ctx_md:
        aug_prompt = ("ã€å¯ç”¨åŸºç«™å€™é€‰ï¼ˆä»…ä¾›å‚è€ƒï¼‰ã€‘\n" + ctx_md + "\n\n" + aug_prompt)
        yield {"type": "log", "channel": "router", "message": f"æä¾› TopK={len(topk)} è¡Œä¸Šä¸‹æ–‡ç»™æ¨¡å‹"}

    # === çœŸæµå¼ï¼šç›´è¿ Ollama ===
    buf = []
    async for delta in stream_from_ollama(aug_prompt):
        buf.append(delta)
        yield {"type": "token", "delta": delta}

    # ï¼ˆå¯é€‰ï¼‰åœ¨æ­¤å¯¹ ''.join(buf) åš split_think_and_final/åéªŒæ ¡éªŒ
    yield {"type": "end"}




@app.post("/api/chat/stream")
async def chat_stream(payload: Dict[str, Any] = Body(...)):
    messages = payload.get("messages") or []
    ctx = payload.get("context") or None
    return StreamingResponse(
        sse(agent_stream(messages, context=ctx)),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache, no-transform",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
        },
    )


@app.post("/api/chat")
def chat_once(payload: Dict[str, Any] = Body(...)):
    messages = payload.get("messages") or []
    prompt = next((m["content"] for m in reversed(messages) if m.get("role") == "user"), "")
    try:
        text = agent(prompt)
        return {"ok": True, "text": str(text)}
    except Exception as e:
        return {"ok": False, "error": str(e)}
    
@app.get("/api/geo/nearby")
def geo_nearby(
    q: Optional[str] = None,
    poi_id: Optional[str] = None,
    city: Optional[str] = None,
    radius_m: int = Query(2000, ge=100, le=20000),
    limit: int = Query(200, ge=1, le=2000),
):
    """
    é€šç”¨â€œPOI é™„è¿‘åŸºç«™â€æ¥å£ï¼ˆæ— éœ€å‰ç«¯æ”¹é€ å³å¯æµ‹è¯•ï¼‰ï¼š
    - ä¼  poi_idï¼šç›´æŸ¥é™„è¿‘
    - ä¼  qï¼ˆå¯é… cityï¼‰ï¼šåš POI æ¶ˆæ­§ï¼›0/1/>1 åˆ†åˆ«è¿”å› none/single/multi ä¸‰ç§å½¢æ€
    è¿”å›å­—æ®µï¼š
      mode: "none" | "single" | "multi"
      candidates: [...]   # å½“ mode=multi
      poi + matches: [...]# å½“ mode=single
    """
    # ç›´æŸ¥ï¼ˆpoi_id ä¼˜å…ˆï¼‰
    if poi_id:
        poi = pois_json.get_poi(poi_id)
        if not poi:
            return {"ok": False, "error": "poi not found"}
        matches = nearby_stations_by_poi(poi, radius_m=radius_m, limit=limit)
        return {"ok": True, "mode": "single", "poi": poi, "matches": matches}

    # æ–‡æœ¬æŸ¥è¯¢ï¼ˆå¸¦æ¶ˆæ­§ï¼‰
    if not q and not city:
        return {"ok": False, "error": "need q or poi_id"}
    prompt = (q or "").strip()
    cands, _ = find_poi_candidates(prompt)
    if city:
        cands = [p for p in cands if p.get("city") == city]
    if not cands:
        return {"ok": True, "mode": "none", "candidates": []}

    if len(cands) == 1:
        poi = cands[0]
        matches = nearby_stations_by_poi(poi, radius_m=radius_m, limit=limit)
        return {"ok": True, "mode": "single", "poi": poi, "matches": matches}

    # å¤šå€™é€‰ï¼šåªè¿”å›â€œå€™é€‰åˆ—è¡¨â€ï¼ˆä¾›ä½ äººå·¥/åç»­å†é€‰ï¼‰
    candidates = [
        {
            "id": p.get("id"),
            "name": p.get("name"),
            "city": p.get("city"),
            "district": p.get("district"),
            "addr_hint": p.get("addr_hint"),
            "lat": p.get("lat"),
            "lng": p.get("lng"),
            "category": p.get("category"),
            "popularity": p.get("popularity"),
        }
        for p in cands
    ]
    return {"ok": True, "mode": "multi", "candidates": candidates}